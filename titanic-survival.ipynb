{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Survival on the Titanic\n",
    "\n",
    "### History\n",
    "Perhaps one of the most infamous shipwrecks in history, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 people on board. Interestingly, by analysing the probability of survival based on few attributes like gender, age, and social status, we can make very accurate predictions on which passengers would survive. Some groups of people were more likely to survive than others, such as women, children, and the upper-class. Therefore, we can learn about the society priorities and privileges at the time.\n",
    "\n",
    "### Assignment:\n",
    "\n",
    "Build a Machine Learning Pipeline, to engineer the features in the data set and predict who is more likely to Survive the catastrophe.\n",
    "\n",
    "Follow the Jupyter notebook below, and complete the missing bits of code, to achieve each one of the pipeline steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import feature_engine.encoding\n",
    "import feature_engine.imputation\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn.base\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"https://www.openml.org/data/get_csv/16826755/phpMYEkMl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace(\"?\", np.nan)  # replace interrogation marks by NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_cabin(row):\n",
    "    \"\"\"Retain only the first cabin if more than 1 are available.\"\"\"\n",
    "    try:\n",
    "        return row.split()[0]\n",
    "    except AttributeError:\n",
    "        return np.nan\n",
    "    \n",
    "data[\"cabin\"] = data[\"cabin\"].apply(get_first_cabin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(passenger):\n",
    "    \"\"\"Extracts the title (Mr, Ms, etc) from the name variable.\"\"\"\n",
    "    line = passenger\n",
    "    if re.search(\"Mrs\", line):\n",
    "        return \"Mrs\"\n",
    "    elif re.search(\"Mr\", line):\n",
    "        return \"Mr\"\n",
    "    elif re.search(\"Miss\", line):\n",
    "        return \"Miss\"\n",
    "    elif re.search(\"Master\", line):\n",
    "        return \"Master\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "    \n",
    "data[\"title\"] = data[\"name\"].apply(get_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"fare\"] = data[\"fare\"].astype(\"float\")\n",
    "data[\"age\"] = data[\"age\"].astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(labels=[\"name\",\"ticket\", \"boat\", \"body\", \"home.dest\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin Assignment\n",
    "\n",
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"survived\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERICAL_VARIABLES = [\"age\", \"fare\"]\n",
    "\n",
    "CATEGORICAL_VARIABLES = [\"sex\", \"cabin\", \"embarked\", \"title\"]\n",
    "\n",
    "CABIN = [\"cabin\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate data into train and test\n",
    "\n",
    "Use the code below for reproducibility. Don't change it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1047, 9), (262, 9))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "    data.drop(target, axis=1), data[target], test_size=0.2, random_state=0\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessors\n",
    "\n",
    "### Class to extract the letter from the variable Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractLetterTransformer(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin):\n",
    "    \"\"\"Extract fist letter of variable.\"\"\"\n",
    "    def __init__(self, variables):\n",
    "        if not isinstance(variables, list):\n",
    "            raise ValueError(\"variables should be a list\")\n",
    "        self.variables = variables\n",
    "           \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Not used here.\"\"\"\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        \n",
    "        for var in self.variables:\n",
    "            X[var] = X[var].str[0]\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "+ Impute categorical variables with string missing\n",
    "+ Add a binary missing indicator to numerical variables with missing data\n",
    "+ Fill NA in original numerical variable with the median\n",
    "+ Extract first letter from cabin\n",
    "+ Group rare Categories\n",
    "+ Perform One hot encoding\n",
    "+ Scale features with standard scaler\n",
    "+ Fit a Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the pipeline\n",
    "titanic_pipe = sklearn.pipeline.Pipeline([\n",
    "\n",
    "    # ===== IMPUTATION =====\n",
    "    # impute categorical variables with string 'missing'\n",
    "    (\n",
    "        \"categorical_imputation\",\n",
    "        feature_engine.imputation.CategoricalImputer(\n",
    "            imputation_method=\"missing\", variables=CATEGORICAL_VARIABLES\n",
    "        )\n",
    "    ),\n",
    "\n",
    "    # add missing indicator to numerical variables\n",
    "    (\n",
    "        \"missing_indicator\", \n",
    "        feature_engine.imputation.AddMissingIndicator(\n",
    "            variables=NUMERICAL_VARIABLES\n",
    "        )\n",
    "    ),\n",
    "\n",
    "    # impute numerical variables with the median\n",
    "    (\n",
    "        \"median_imputation\", \n",
    "        feature_engine.imputation.MeanMedianImputer(\n",
    "            imputation_method=\"median\", variables=NUMERICAL_VARIABLES\n",
    "        )\n",
    "    ),\n",
    "\n",
    "\n",
    "    # Extract first letter from cabin\n",
    "    (\"extract_letter\", ExtractLetterTransformer(CABIN)),\n",
    "\n",
    "\n",
    "    # == CATEGORICAL ENCODING ======\n",
    "    # remove categories present in less than 5% of the observations (0.05)\n",
    "    # group them in one category called 'Rare'\n",
    "    (\n",
    "        \"rare_label_encoder\", \n",
    "        feature_engine.encoding.RareLabelEncoder(\n",
    "            tol=0.05, n_categories=1, variables=CATEGORICAL_VARIABLES\n",
    "        )\n",
    "    ),\n",
    "\n",
    "\n",
    "    # encode categorical variables using one hot encoding into k-1 variables\n",
    "    (\n",
    "        \"categorical_encoder\", \n",
    "        feature_engine.encoding.OneHotEncoder(\n",
    "            drop_last=True, variables=CATEGORICAL_VARIABLES\n",
    "        )\n",
    "    ),\n",
    "\n",
    "    # scale using standardization\n",
    "    (\"scaler\", sklearn.preprocessing.StandardScaler()),\n",
    "\n",
    "    # logistic regression (use C=0.0005 and random_state=0)\n",
    "    ('Logit', sklearn.linear_model.LogisticRegression(C=0.0005, random_state=0)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;categorical_imputation&#x27;,\n",
       "                 CategoricalImputer(variables=[&#x27;sex&#x27;, &#x27;cabin&#x27;, &#x27;embarked&#x27;,\n",
       "                                               &#x27;title&#x27;])),\n",
       "                (&#x27;missing_indicator&#x27;,\n",
       "                 AddMissingIndicator(variables=[&#x27;age&#x27;, &#x27;fare&#x27;])),\n",
       "                (&#x27;median_imputation&#x27;,\n",
       "                 MeanMedianImputer(variables=[&#x27;age&#x27;, &#x27;fare&#x27;])),\n",
       "                (&#x27;extract_letter&#x27;,\n",
       "                 ExtractLetterTransformer(variables=[&#x27;cabin&#x27;])),\n",
       "                (&#x27;rare_label_encoder&#x27;,\n",
       "                 RareLabelEncoder(n_categories=1,\n",
       "                                  variables=[&#x27;sex&#x27;, &#x27;cabin&#x27;, &#x27;embarked&#x27;,\n",
       "                                             &#x27;title&#x27;])),\n",
       "                (&#x27;categorical_encoder&#x27;,\n",
       "                 OneHotEncoder(drop_last=True,\n",
       "                               variables=[&#x27;sex&#x27;, &#x27;cabin&#x27;, &#x27;embarked&#x27;,\n",
       "                                          &#x27;title&#x27;])),\n",
       "                (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;Logit&#x27;, LogisticRegression(C=0.0005, random_state=0))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;categorical_imputation&#x27;,\n",
       "                 CategoricalImputer(variables=[&#x27;sex&#x27;, &#x27;cabin&#x27;, &#x27;embarked&#x27;,\n",
       "                                               &#x27;title&#x27;])),\n",
       "                (&#x27;missing_indicator&#x27;,\n",
       "                 AddMissingIndicator(variables=[&#x27;age&#x27;, &#x27;fare&#x27;])),\n",
       "                (&#x27;median_imputation&#x27;,\n",
       "                 MeanMedianImputer(variables=[&#x27;age&#x27;, &#x27;fare&#x27;])),\n",
       "                (&#x27;extract_letter&#x27;,\n",
       "                 ExtractLetterTransformer(variables=[&#x27;cabin&#x27;])),\n",
       "                (&#x27;rare_label_encoder&#x27;,\n",
       "                 RareLabelEncoder(n_categories=1,\n",
       "                                  variables=[&#x27;sex&#x27;, &#x27;cabin&#x27;, &#x27;embarked&#x27;,\n",
       "                                             &#x27;title&#x27;])),\n",
       "                (&#x27;categorical_encoder&#x27;,\n",
       "                 OneHotEncoder(drop_last=True,\n",
       "                               variables=[&#x27;sex&#x27;, &#x27;cabin&#x27;, &#x27;embarked&#x27;,\n",
       "                                          &#x27;title&#x27;])),\n",
       "                (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;Logit&#x27;, LogisticRegression(C=0.0005, random_state=0))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CategoricalImputer</label><div class=\"sk-toggleable__content\"><pre>CategoricalImputer(variables=[&#x27;sex&#x27;, &#x27;cabin&#x27;, &#x27;embarked&#x27;, &#x27;title&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AddMissingIndicator</label><div class=\"sk-toggleable__content\"><pre>AddMissingIndicator(variables=[&#x27;age&#x27;, &#x27;fare&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MeanMedianImputer</label><div class=\"sk-toggleable__content\"><pre>MeanMedianImputer(variables=[&#x27;age&#x27;, &#x27;fare&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtractLetterTransformer</label><div class=\"sk-toggleable__content\"><pre>ExtractLetterTransformer(variables=[&#x27;cabin&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RareLabelEncoder</label><div class=\"sk-toggleable__content\"><pre>RareLabelEncoder(n_categories=1,\n",
       "                 variables=[&#x27;sex&#x27;, &#x27;cabin&#x27;, &#x27;embarked&#x27;, &#x27;title&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop_last=True, variables=[&#x27;sex&#x27;, &#x27;cabin&#x27;, &#x27;embarked&#x27;, &#x27;title&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.0005, random_state=0)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('categorical_imputation',\n",
       "                 CategoricalImputer(variables=['sex', 'cabin', 'embarked',\n",
       "                                               'title'])),\n",
       "                ('missing_indicator',\n",
       "                 AddMissingIndicator(variables=['age', 'fare'])),\n",
       "                ('median_imputation',\n",
       "                 MeanMedianImputer(variables=['age', 'fare'])),\n",
       "                ('extract_letter',\n",
       "                 ExtractLetterTransformer(variables=['cabin'])),\n",
       "                ('rare_label_encoder',\n",
       "                 RareLabelEncoder(n_categories=1,\n",
       "                                  variables=['sex', 'cabin', 'embarked',\n",
       "                                             'title'])),\n",
       "                ('categorical_encoder',\n",
       "                 OneHotEncoder(drop_last=True,\n",
       "                               variables=['sex', 'cabin', 'embarked',\n",
       "                                          'title'])),\n",
       "                ('scaler', StandardScaler()),\n",
       "                ('Logit', LogisticRegression(C=0.0005, random_state=0))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions and evaluate model performance\n",
    "\n",
    "Determine:\n",
    "- roc-auc\n",
    "- accuracy\n",
    "\n",
    "**Important, remember that to determine the accuracy, you need the outcome 0, 1, referring to survived or not. But to determine the roc-auc you need the probability of survival.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train roc-auc: 0.8450386398763523\n",
      "train accuracy: 0.7220630372492837\n",
      "\n",
      "train roc-auc: 0.8354629629629629\n",
      "train accuracy: 0.7137404580152672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train set\n",
    "y_pred = titanic_pipe.predict_proba(X_train)[:,1]\n",
    "\n",
    "print(\"train roc-auc: {}\".format(sklearn.metrics.roc_auc_score(y_train, y_pred)))\n",
    "print(\"train accuracy: {}\".format(sklearn.metrics.accuracy_score(y_train, np.round(y_pred))))\n",
    "print()\n",
    "\n",
    "# test set\n",
    "y_pred_test = titanic_pipe.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"train roc-auc: {}\".format(sklearn.metrics.roc_auc_score(y_test, y_pred_test)))\n",
    "print(\"train accuracy: {}\".format(sklearn.metrics.accuracy_score(y_test, np.round(y_pred_test))))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! Well done\n",
    "\n",
    "**Keep this code safe, as we will use this notebook later on, to build production code, in our next assignement!!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
